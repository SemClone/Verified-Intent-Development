# VID Real-World Examples

**Five concrete scenarios showing VID principles in action**

These examples demonstrate how VID practices catch real issues and prevent production problems. Each includes the code, the problem, and how VID would have prevented it.

---

## Example 1: Subtle Logic Bug Caught by Verification Ritual

### The Scenario

A developer asked an AI assistant to create a function to calculate user subscription renewal dates.

### The Generated Code

```javascript
function calculateRenewalDate(subscriptionStart, planType) {
  const renewalDate = new Date(subscriptionStart);

  if (planType === 'monthly') {
    renewalDate.setMonth(renewalDate.getMonth() + 1);
  } else if (planType === 'annual') {
    renewalDate.setFullYear(renewalDate.getFullYear() + 1);
  }

  return renewalDate;
}
```

### The Problem

**This code looks correct but has a subtle bug:**

When a subscription starts on January 31st and renews monthly, `setMonth(2)` (March) adjusts to March 3rd because February doesn't have 31 days. This causes:
- User charged on Jan 31, then March 3, then March 31, then May 3...
- Inconsistent billing dates
- Customer support nightmare

### Without VID

**Developer thought process:**
- "Looks good"
- Tests pass for Jan 15 → Feb 15 ✓
- Ships to production
- **3 months later:** Billing complaints from customers subscribed on the 29th-31st

### With VID

**Verification Ritual (15 minutes, Moderate Trust):**

1. **Read the code** ✓
2. **Verify against intent** ✓
3. **Check edge cases:**
   - "What happens on the 31st of a month?"
   - Manual test: `calculateRenewalDate('2024-01-31', 'monthly')`
   - Result: `2024-03-03` ❌
   - **BUG FOUND**

4. **Fix before commit:**

```javascript
function calculateRenewalDate(subscriptionStart, planType) {
  const start = new Date(subscriptionStart);
  const dayOfMonth = start.getDate();

  let renewalDate = new Date(subscriptionStart);

  if (planType === 'monthly') {
    renewalDate.setMonth(renewalDate.getMonth() + 1);
    // Preserve original day of month
    renewalDate.setDate(Math.min(dayOfMonth, getLastDayOfMonth(renewalDate)));
  } else if (planType === 'annual') {
    renewalDate.setFullYear(renewalDate.getFullYear() + 1);
    // Handle Feb 29 on non-leap years
    renewalDate.setDate(Math.min(dayOfMonth, getLastDayOfMonth(renewalDate)));
  }

  return renewalDate;
}

function getLastDayOfMonth(date) {
  return new Date(date.getFullYear(), date.getMonth() + 1, 0).getDate();
}
```

**Time invested:** 15 minutes
**Time saved:** Hours of debugging + customer support + reputation damage

**VID Principles Applied:**
- ✅ **Principle 2 (Graduated Trust):** Moderate Trust verification (15 min) matched to financial impact risk
- ✅ **Principle 1 (Intent Before Generation):** Edge case thinking ("what happens on the 31st?") came from upfront intent specification
- ✅ **Practice: Verification Ritual:** Systematic edge case testing caught the bug before production

**Key Lesson:** Edge case verification is where AI-generated code most often fails. The code *looks* correct and handles the happy path perfectly. Only systematic verification catches month-boundary bugs.

---

## Example 2: Provenance Awareness Prevents Regression

### The Scenario

Six months ago, an AI assistant generated an authentication middleware. Today, a developer needs to modify it to add rate limiting.

### The Original Code (AI-Generated)

```python
# Generated by AI - 2024-06-15
# Verified by: @sarah - Standard verification
def authenticate_request(request):
    """Verify JWT token and attach user to request."""
    token = request.headers.get('Authorization', '').replace('Bearer ', '')

    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])
        request.user = User.get(payload['user_id'])
        return True
    except jwt.ExpiredSignatureError:
        return False
    except jwt.InvalidTokenError:
        return False
```

### Without Provenance Awareness

**Developer thinks:** "I wrote this, I understand it."

**Modification:**
```python
def authenticate_request(request):
    """Verify JWT token, check rate limits, attach user."""
    token = request.headers.get('Authorization', '').replace('Bearer ', '')

    payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])

    # Add rate limiting
    if rate_limiter.is_exceeded(payload['user_id']):
        return False

    request.user = User.get(payload['user_id'])
    return True
```

**What broke:**
- Removed try-except blocks (didn't understand they were essential)
- Now raises unhandled exceptions on invalid tokens
- **500 errors instead of graceful 401s**
- Production incident at 2AM

### With Provenance Awareness

**Developer sees comment:** `# Generated by AI - 2024-06-15`

**Thought process:**
- "I didn't write this originally"
- "I should verify I understand it before modifying"
- "Why are there try-except blocks?"
- Checks original intent specification: "Must handle expired/invalid tokens gracefully"

**Modification (safe):**
```python
# Modified from AI-generated code - 2024-12-15
# Original: 2024-06-15 (AI-generated, verified by @sarah)
# Changes: Added rate limiting (verified by @mike)
def authenticate_request(request):
    """Verify JWT token, check rate limits, attach user."""
    token = request.headers.get('Authorization', '').replace('Bearer ', '')

    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])

        # NEW: Rate limiting
        if rate_limiter.is_exceeded(payload['user_id']):
            return False

        request.user = User.get(payload['user_id'])
        return True
    except jwt.ExpiredSignatureError:
        return False
    except jwt.InvalidTokenError:
        return False
```

**Provenance hygiene saved:**
- Production incident avoided
- Original error handling preserved
- Clear modification history for next developer

**VID Principles Applied:**
- ✅ **Principle 4 (Provenance Awareness):** Comment marking AI-generated code triggered appropriate caution
- ✅ **Principle 3 (Understanding Over Acceptance):** Developer verified understanding before modifying unfamiliar code
- ✅ **Practice: Provenance Hygiene:** Commit messages and code comments documented who generated what and when

**Key Lesson:** AI-generated code looks identical to human-written code six months later. Without provenance markers, developers assume they understand code they didn't write and don't remember. This leads to cargo-cult modifications that break subtle invariants.

---

## Example 3: Risk Miscalibration

### The Scenario

A developer needs to add a feature to allow users to delete their accounts.

### Initial Risk Assessment (Wrong)

**Developer thinks:**
- "This is straightforward CRUD"
- "Just add a DELETE endpoint"
- **Risk score: 8 (High Trust)**
- Verification time: 5 minutes

### The Generated Code

```javascript
app.delete('/api/users/:userId', async (req, res) => {
  await db.users.delete({ id: req.params.userId });
  res.json({ success: true });
});
```

### The Problem

**Actual considerations missed:**
- **Impact:** Deletes all user data (irreversible) → Score: 5
- **Reversibility:** Cannot undo → Score: 5
- **Exposure:** Affects individual users → Score: 3
- **Compliance:** GDPR requires specific deletion process → Score: 8

**Actual risk score: (5×3) + (5×2) + (3×2) + 8 = 39 (Minimal Trust)**

Should have required:
- 1-3 hours verification
- Peer review
- Legal/compliance review
- Production testing plan

### What This Code Missed

1. **Authentication/Authorization:** Anyone can delete any account
2. **GDPR Compliance:** Must anonymize, not delete (for audit trail)
3. **Related Data:** Orphans user's posts, comments, purchases
4. **Cascading Effects:** Breaks foreign key relationships
5. **Audit Trail:** No record of deletion
6. **Grace Period:** No "undo" window
7. **Notifications:** User not notified
8. **Billing:** Active subscriptions not cancelled

### With Proper Risk Calibration

**Corrected assessment:**
- This is a critical, irreversible operation
- Compliance requirements apply
- Requires 2+ hours verification + peer review

**Proper implementation:**
```javascript
app.delete('/api/users/:userId',
  requireAuth(),
  requireOwnershipOr('admin'),
  async (req, res) => {
    const userId = req.params.userId;

    // Start transaction
    const transaction = await db.transaction();

    try {
      // 1. Validate user exists and can be deleted
      const user = await db.users.findOne({ id: userId });
      if (!user) throw new NotFoundError();
      if (user.deletion_requested_at) {
        throw new Error('Deletion already in progress');
      }

      // 2. Cancel active subscriptions
      await cancelActiveSubscriptions(userId, transaction);

      // 3. Initiate GDPR-compliant anonymization
      await db.users.update(
        { id: userId },
        {
          deletion_requested_at: new Date(),
          deletion_scheduled_for: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000),
          status: 'deletion_pending'
        },
        { transaction }
      );

      // 4. Queue background job for actual anonymization
      await queue.add('anonymize-user-data', {
        userId,
        scheduledFor: Date.now() + 30 * 24 * 60 * 60 * 1000
      });

      // 5. Audit log
      await audit.log({
        action: 'user_deletion_requested',
        userId,
        requestedBy: req.user.id,
        scheduledFor: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000)
      });

      // 6. Notify user
      await sendDeletionConfirmationEmail(user.email);

      await transaction.commit();

      res.json({
        success: true,
        message: 'Account deletion scheduled for 30 days from now',
        cancellable_until: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000)
      });

    } catch (error) {
      await transaction.rollback();
      throw error;
    }
});
```

**Lesson:** "Simple" operations can have complex requirements. Proper risk assessment prevents disasters.

**VID Principles Applied:**
- ✅ **Principle 2 (Graduated Trust):** Corrected risk calibration from High Trust (8) to Minimal Trust (39) changed everything
- ✅ **Principle 5 (Continuous Calibration):** Realized initial assessment was wrong and adjusted before deployment
- ✅ **Practice: Risk Assessment (Appendix D):** Using the full rubric (Impact + Reversibility + Exposure + Compliance) revealed the true risk

**Key Lesson:** Familiarity bias is dangerous. "I've done CRUD operations before" doesn't mean *this* DELETE is low-risk. Systematically assessing all four risk factors (especially compliance!) prevents catastrophic under-verification.

---

## Example 4: Missing Intent Leads to Wrong Solution

### The Scenario

A developer wants to "improve query performance for the user dashboard."

### Without Intent Specification

**Prompt to AI:** "Optimize this query"

```sql
SELECT * FROM users
JOIN posts ON users.id = posts.user_id
WHERE users.active = true;
```

**AI generates:**
```sql
SELECT * FROM users
JOIN posts ON users.id = posts.user_id
WHERE users.active = true
LIMIT 100;
```

**What happened:**
- Query is faster ✓
- But now dashboard only shows 100 posts total (not per user)
- **Completely wrong behavior**
- Bug makes it to production

### With Intent Specification (2 minutes upfront)

**Developer writes intent:**

```
Goal: Speed up dashboard query that shows all posts for active users

Current problem:
- Query takes 3 seconds
- Loads all users + all their posts
- 100,000+ rows scanned

Requirements:
- Must show ALL posts for active users (not just first N)
- Dashboard paginates on frontend
- Query should load in <500ms

Edge cases:
- Users with thousands of posts
- New users with no posts
- Deleted posts should be excluded

How I'll verify:
- Test with user who has 1000+ posts
- Check query execution plan
- Measure actual query time

Risk level: Moderate (impacts all users, but reversible)
```

**Now the AI gets better context:**

```sql
-- Optimization: Add index and filter deleted posts in JOIN
CREATE INDEX idx_posts_user_active ON posts(user_id, created_at)
  WHERE deleted_at IS NULL;

-- Optimized query
SELECT
  users.id,
  users.name,
  posts.id AS post_id,
  posts.title,
  posts.created_at
FROM users
JOIN posts ON users.id = posts.user_id AND posts.deleted_at IS NULL
WHERE users.active = true
ORDER BY posts.created_at DESC;
```

**Verification reveals:**
- Still slow for users with many posts
- Real solution: Paginate at query level, not frontend

**Final solution:**
```sql
-- Dashboard loads first page of posts per user
SELECT
  users.id,
  users.name,
  posts.id AS post_id,
  posts.title,
  posts.created_at
FROM users
JOIN LATERAL (
  SELECT * FROM posts
  WHERE posts.user_id = users.id
    AND posts.deleted_at IS NULL
  ORDER BY created_at DESC
  LIMIT 20
) posts ON true
WHERE users.active = true
ORDER BY users.last_active DESC
LIMIT 50;
```

**Intent specification prevented:**
- Wrong solution (LIMIT 100)
- Performance "optimization" that broke functionality
- Multiple rounds of back-and-forth debugging

**Time saved:** Hours of debugging + production rollback

**VID Principles Applied:**
- ✅ **Principle 1 (Intent Before Generation):** 2 minutes specifying requirements prevented deploying a "faster but wrong" solution
- ✅ **Principle 3 (Understanding Over Acceptance):** Verification step ("test with user who has 1000+ posts") revealed the real problem
- ✅ **Practice: Intent Specification (Chapter 9):** Documenting edge cases and success criteria guided both AI and human judgment

**Key Lesson:** AI optimizes for what you ask, not what you need. "Make it faster" without context produces faster-but-wrong code. Spending 2 minutes on intent specification saves hours of debugging broken optimizations.

---

## Example 5: Understanding Debt Compounds Over Time

### Month 1: The Initial Generation

A junior developer asks AI to create a caching layer:

```python
# AI-generated - Not fully understood by developer
class CacheManager:
    def __init__(self):
        self._cache = {}
        self._locks = {}

    def get_or_compute(self, key, compute_fn, ttl=3600):
        if key in self._cache:
            value, expiry = self._cache[key]
            if time.time() < expiry:
                return value

        # Double-checked locking pattern
        if key not in self._locks:
            self._locks[key] = threading.Lock()

        with self._locks[key]:
            # Check again inside lock
            if key in self._cache:
                value, expiry = self._cache[key]
                if time.time() < expiry:
                    return value

            value = compute_fn()
            self._cache[key] = (value, time.time() + ttl)
            return value
```

**Developer thinks:** "Looks good, tests pass, ship it"
**Understanding level:** 30% (doesn't understand double-checked locking or why it's needed)

### Month 3: First Modification

Add cache invalidation:

```python
def invalidate(self, key):
    if key in self._cache:
        del self._cache[key]  # BUG: Doesn't clean up lock
```

**Problem:** Lock dict grows forever (memory leak)
**Not caught:** Developer doesn't understand lock management

### Month 6: Second Modification

Add cache statistics:

```python
def get_or_compute(self, key, compute_fn, ttl=3600):
    self.stats['requests'] += 1  # BUG: Not thread-safe

    if key in self._cache:
        value, expiry = self._cache[key]
        if time.time() < expiry:
            self.stats['hits'] += 1  # BUG: Race condition
            return value

    # ... rest unchanged
```

**Problem:** Race conditions on stats counter
**Not caught:** Developer doesn't understand threading implications

### Month 9: Third Modification

Add cache warming:

```python
def warm_cache(self, items):
    for key, compute_fn in items:
        self._cache[key] = (compute_fn(), time.time() + 3600)
        # BUG: Bypasses locking, causes race conditions
```

**Problem:** Direct cache writes without locking
**Not caught:** Developer still doesn't understand the locking pattern

### Month 12: Production Crisis

**Symptoms:**
- Random cache corruption
- Memory leaks (10GB+ cache)
- Race conditions causing data inconsistencies
- Occasional deadlocks

**Cost:**
- 3 days of senior engineer debugging
- Production incidents
- Data inconsistencies requiring manual fixes
- Complete rewrite needed

### The Understanding Debt Trajectory

```
Month 1:  30% understanding → Ship with hidden issues
Month 3:  25% understanding → Introduce memory leak
Month 6:  20% understanding → Add race conditions
Month 9:  15% understanding → Bypass safety mechanisms
Month 12: CRISIS → 3 days to understand + rewrite
```

**Total cost:** 3 days senior engineer time + production incidents + data cleanup

### With VID (Month 1)

**Verification ritual includes:** "Explain this code to yourself"

**Developer realizes:**
- "I don't understand why there are two cache checks"
- "What is this lock dict for?"
- "Why check the cache again inside the lock?"

**Invokes Principle 3:** Understanding Over Acceptance

**Actions:**
- Researches double-checked locking
- Understands race conditions
- Documents why pattern is needed
- Tests concurrent access
- **Builds 90% understanding**

**Time invested:** 1 hour

**Future modifications (Months 3, 6, 9):**
- Developer understands threading implications
- Knows to use locks for all cache mutations
- Knows to use locks for stats updates
- Avoids all bugs from original timeline

**Total cost:** 1 hour upfront

**Savings:** 3 days debugging + production incidents + rewrites

**VID Principles Applied:**
- ✅ **Principle 3 (Understanding Over Acceptance):** Invested 1 hour to understand threading patterns prevented months of compounding problems
- ✅ **Principle 5 (Continuous Calibration):** Each modification without understanding made the next one harder—learning loop prevented the debt spiral
- ✅ **Practice: Learning Loop (Chapter 11):** Tracking outcomes (3 incidents in 6 months) revealed systematic understanding gap

**Key Lesson:** Understanding debt compounds exponentially. The first modification you make without understanding sets a precedent. Each subsequent modification builds on misunderstanding, creating increasingly fragile code. One hour invested early prevents days lost later.

---

## Common Patterns Across Examples

### What VID Caught

1. **Edge cases** (Example 1: Jan 31st subscription)
2. **Missing context** (Example 2: Why try-except existed)
3. **Risk underestimation** (Example 3: "Simple" delete)
4. **Wrong requirements** (Example 4: What "optimize" meant)
5. **Compounding debt** (Example 5: Understanding gap)

### How Much Time VID Takes

- Example 1: 15 minutes → Saved hours + customer issues
- Example 2: 2 minutes (reading comment) → Prevented production incident
- Example 3: Proper verification (2 hours) → Avoided compliance violation
- Example 4: Intent spec (2 minutes) → Got right solution first try
- Example 5: Understanding (1 hour) → Avoided 3-day crisis

### The VID Investment ROI

**Time invested:** Minutes to hours per task
**Time saved:** Hours to days of debugging + production incidents
**ROI:** 10x-100x return on verification time

---

## Using These Examples

### For Training

Walk through each example with your team:
1. Show the generated code
2. Ask: "What could go wrong?"
3. Reveal the problem
4. Demonstrate how VID would catch it

### For Onboarding

New team members should:
- Read all five examples
- Identify which VID principle each demonstrates
- Practice applying that principle to their own work

### For Calibration

When team members struggle with verification:
- Point to relevant example
- Show concrete time savings
- Build verification habits through repetition

---

## Attribution

**Verified Intent Development (VID) Methodology**
Created by Oscar Valenzuela (SEMCL.ONE Community) - See [AUTHORS.md](./AUTHORS.md) for all contributors
Licensed under CC BY-SA 4.0

https://github.com/SemClone/Verified-Intent-Development

---

*Real bugs. Real prevention. Real ROI.*
