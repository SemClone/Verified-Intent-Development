## Chapter 2: Why Existing Approaches Fall Short

Before presenting VID, we should understand why you can't just apply existing methodologies to AI-augmented development. The failures aren't superficial — they're structural.

### Agile's Blind Spot

Agile's core insight is that requirements change, so we should plan in short iterations and adapt based on feedback. This remains valid. But Agile assumes the expensive operation is writing code, so its ceremonies optimize for coordination and prioritization of coding effort.

Standups ask: "What did you code yesterday? What will you code today?"

Sprint planning asks: "How much can we code this sprint?"

Retrospectives ask: "How can we code more effectively?"

Notice what's missing: systematic attention to verification.

Agile has testing, of course. But testing in Agile is typically focused on "does the feature work?" not "is this code trustworthy?" When code is written by humans who understand what they wrote, this is often sufficient. The developer's understanding provides implicit verification.

When code is generated by AI, that implicit verification disappears. The developer may not fully understand the generated code. "It passes tests" is not the same as "I understand why it's correct."

Agile provides no framework for:
- Deciding how much verification a piece of code needs
- Tracking where code came from (human vs. AI)
- Adjusting process based on code provenance
- Building verification skills as a core competency

### The "Just Add AI" Fallacy

Many teams try to integrate AI by simply adding it to their existing workflow:

"We do Scrum, but now developers use Copilot."

This approach fails because it treats AI as a faster typewriter rather than a fundamental shift in how code comes into existence. The methodology remains optimized for the old constraint while the actual constraint has changed.

Symptoms of this failure:
- Developers generate more code but defect rates increase
- Sprint velocity appears higher but production incidents rise
- Technical debt accumulates faster than before
- Code reviews become rubber stamps because there's too much to review carefully
- No one knows which parts of the codebase were AI-generated

### The Vibe Coding Trap

On the opposite extreme, some developers abandon methodology entirely. "Vibe coding" — generating code through natural language prompts with minimal structure — produces impressive demos but dangerous production systems.

Vibe coding fails because:

**No verification criteria.** Without explicit criteria for correctness, there's no way to know if generated code is right. "It seems to work" is not verification.

**No risk awareness.** All code is treated equally, whether it's a utility function or an authentication handler.

**No learning loop.** Without systematic tracking, teams can't learn which patterns produce good outcomes.

**No accountability.** When everyone is prompting AI, no one is responsible for understanding the result.

Vibe coding works for prototypes and experiments. It's actively dangerous for production systems.

### Emerging AIDD Frameworks

Several "AI-Driven Development" frameworks have emerged attempting to address these gaps. They typically share these characteristics:

- Replace sprints with shorter cycles ("bolts")
- Emphasize specification as input to AI
- Add AI agents for various development tasks
- Provide prompt templates and workflows

These frameworks improve on naive AI adoption, but most share a fundamental flaw: **they optimize for generation velocity, not verification confidence**.

Questions they don't adequately answer:
- How do you know AI-generated code is correct?
- When should humans verify vs. trust automation?
- How do you build verification skills in developers?
- How do you adapt verification to risk level?
- How do you maintain understanding as AI writes more code?

VID addresses these questions directly.

---

